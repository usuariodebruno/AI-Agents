# Configurações do Agente de IA

# --- OpenAI (para a funcionalidade RAG) ---
# Necessário para que o rag_pipeline.py possa gerar respostas baseadas no código.
# Obtenha sua chave em: https://platform.openai.com/api-keys
OPENAI_API_KEY="sk-SUA_CHAVE_AQUI"

# Modelo da OpenAI a ser usado. O padrão é "gpt-3.5-turbo".
OPENAI_MODEL="gpt-3.5-turbo"


# --- API de Dados (Opcional) ---
# URL de uma API para carregar perguntas e respostas (QA) dinamicamente.
# Se não for definida, o sistema usará o cache local ou os dados embutidos em qa_data.py.
# QA_API_URL="http://exemplo.com/api/qa"

# --- API de Dados (Opcional) ---
# URL de uma API para carregar perguntas e respostas (QA) dinamicamente.
# Se não for definida, o sistema usará o cache local ou os dados embutidos em qa_data.py.
# QA_API_URL="http://exemplo.com/api/qa"

# --- Provedor de LLM (Escolha um) ---
# Defina qual LLM usar: "openai" ou "gemini". O padrão é "openai".
LLM_PROVIDER="gemini"

# --- Google Gemini ---
# Necessário se LLM_PROVIDER for "gemini".
# Obtenha sua chave em: https://aistudio.google.com/app/apikey
GEMINI_API_KEY="SUA_CHAVE_AQUI"

# --- Configuração da Aplicação ---
# Nome do serviço/projeto a ser mencionado na saudação inicial.
SERVICE_NAME="VUMBORA"